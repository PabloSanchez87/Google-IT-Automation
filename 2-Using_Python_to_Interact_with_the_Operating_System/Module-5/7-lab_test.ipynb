{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Notebook - Unit Tests and Edge Cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "  \n",
    "my_txt = \"An investment in knowledge pays the best interest.\"\n",
    "\n",
    "def LetterCompiler(txt):\n",
    "    result = re.findall(r'([a-c]).', txt)\n",
    "    return result\n",
    "\n",
    "print(LetterCompiler(my_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, you can see that the `LetterCompiler( )` function finds all matches for the letters a through c in an input string if followed by another character and returns them as a list of strings, with each string representing one match. Nice.\n",
    "\n",
    "**But can we be sure that this function will always do what we expect it to do?** `We need to write code to help us catch mistakes, errors and bugs.` This code should automate the process of checking if the returned value of our code matches the expectations by dynamically feeding into it test cases. Since we're dynamically feeding in different strings, it would be prudent to create unit tests for our code. We can use the module unittest for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [--durations N] [-f]\n",
      "                             [-c] [-b] [-k TESTNAMEPATTERNS]\n",
      "                             [tests ...]\n",
      "ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/pablost/.local/share/jupyter/runtime/kernel-v34e164d8eeee4e32727fdcb9adff3e1ccc0eefdcd.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablost/Google_IT_Automation_With_Python_Course/.env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCompiler(unittest.TestCase):\n",
    "\n",
    "    def test_basic(self):\n",
    "        testcase = \"The best preparation for tomorrow is doing your best today.\"\n",
    "        expected = ['b', 'a', 'a', 'b', 'a']\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)\n",
    "        \n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SystemExit: True means an error occurred, as expected. The reason is that `unittest.main( )` looks at sys.argv. In Jupyter, by default, **the first parameter of sys.argv is what started the Jupyter kernel which is not the case when executing it from the command line.** This default parameter is passed into unittest.main( ) as an attribute when you don't explicitly pass it attributes and is therefore what causes the error about the kernel connection file not being a valid attribute. Passing an explicit list to unittest.main( ) prevents it from looking at sys.argv.\n",
    "\n",
    "Let's pass it the list ['first-arg-is-ignored'] for example. In addition, we will pass it the parameter exit = False to prevent unittest.main( ) from shutting down the kernel process. Run the following cell with the argv and exit parameters passed into unittest.main( ) to rerun your automatic test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_basic (__main__.TestCompiler.test_basic) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fb8ae680c20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCompiler(unittest.TestCase):\n",
    "\n",
    "    def test_basic(self):\n",
    "        testcase = \"The best preparation for tomorrow is doing your best today.\"\n",
    "        expected = ['b', 'a', 'a', 'b', 'a']\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)   \n",
    "    \n",
    "unittest.main(argv = ['first-arg-is-ignored'], exit = False, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully filled in the gaps to create an automatic test that verifies whether input strings have the correct list of string matches.\n",
    "\n",
    "This is great work so far, but your automatic test includes only one test case. You need to make it grow. You can feed in more strings as test cases to test whether your code works in the general case. But you should also see what happens when you give it some input that you might not expect it to run into under normal operations.\n",
    "\n",
    "`Edge cases` are inputs to code that produce unexpected results, and are found at the extreme ends of the ranges of input we imagine programs will typically work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_basic (__main__.TestCompiler.test_basic) ... ok\n",
      "test_empty (__main__.TestCompiler.test_empty) ... ok\n",
      "test_only_spaces (__main__.TestCompiler.test_only_spaces) ... ok\n",
      "test_symbols_and_numbers (__main__.TestCompiler.test_symbols_and_numbers) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f7dd8ec74d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestCompiler(unittest.TestCase):\n",
    "\n",
    "    def test_basic(self):\n",
    "        testcase = \"The best preparation for tomorrow is doing your best today.\"\n",
    "        expected = ['b', 'a', 'a', 'b', 'a']\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)\n",
    "        \n",
    "# EDGE CASESÃ§\n",
    "    # Empty string\n",
    "    def test_empty(self):\n",
    "        testcase = \"\"\n",
    "        expected = []\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)\n",
    "    \n",
    "    # String with only spaces\n",
    "    def test_only_spaces(self):\n",
    "        testcase = \"     \"\n",
    "        expected = []  # No letters should be compiled\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)    \n",
    "        \n",
    "    # String with only symbols or numbers\n",
    "    def test_symbols_and_numbers(self):\n",
    "        testcase = \"12345!@#$%\"\n",
    "        expected = []  # No letters should be compiled\n",
    "        self.assertEqual(LetterCompiler(testcase), expected)\n",
    "\n",
    "# RUN THE TESTS\n",
    "\n",
    "unittest.main(argv = ['first-arg-is-ignored'], exit = False, verbosity=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
